{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import time \n",
    "import math\n",
    "\n",
    "from common import (\n",
    "    set_seed, find_episodes, load_annotations_json, video_path_for_episode,\n",
    "    load_refs_for_episode, EmbeddingMatcher, build_template, YOLOProposals,\n",
    "    l2_normalize, iou_xyxy, frame_to_boxes, TemporalHead, IoUHead,\n",
    ")\n",
    "\n",
    "\n",
    "def build_split(split_file):\n",
    "    with open(split_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        sp = json.load(f)\n",
    "    return sp[\"train_ids\"], sp[\"val_ids\"]\n",
    "\n",
    "\n",
    "def label_frame_candidates(gt_map, frame_idx, props):\n",
    "    if frame_idx not in gt_map: return [0.0]*len(props), [0.0]*len(props)\n",
    "    y = []; ious=[]\n",
    "    for b in props:\n",
    "        best = 0.0\n",
    "        for g in gt_map[frame_idx]:\n",
    "            best = max(best, iou_xyxy(b,g))\n",
    "        y.append(1.0 if best >= 0.5 else 0.0)\n",
    "        ious.append(best)\n",
    "    return y, ious\n",
    "\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--data_root\", required=True)\n",
    "    ap.add_argument(\"--split_file\", required=True)\n",
    "    ap.add_argument(\"--epochs\", type=int, default=5)\n",
    "    ap.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    ap.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "    ap.add_argument(\"--freeze_backbone\", action=\"store_true\")\n",
    "    ap.add_argument(\"--save_ckpt\", default=\"./ckpts/heads_dev.pt\")\n",
    "    ap.add_argument(\"--imgsz\", type=int, default=960)\n",
    "    ap.add_argument(\"--max_props\", type=int, default=200)\n",
    "    ap.add_argument(\"--conf\", type=float, default=0.005)\n",
    "    ap.add_argument(\"--nms_iou\", type=float, default=0.60)\n",
    "    ap.add_argument(\"--temporal_T\", type=int, default=15)\n",
    "    ap.add_argument(\"--yolo_ckpt\", type=str, default=None)\n",
    "    ap.add_argument(\"--debug\", action=\"store_true\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    set_seed(1337)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    Path(args.save_ckpt).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_ids, val_ids = build_split(args.split_file)\n",
    "    print(f\"[SPLIT] train={len(train_ids)} val={len(val_ids)}\")\n",
    "\n",
    "    props_engine = YOLOProposals(conf=args.conf, iou=args.nms_iou, imgsz=args.imgsz,\n",
    "                                 max_candidates=args.max_props, device=0,\n",
    "                                 yolo_on=True, yolo_ckpt=args.yolo_ckpt, debug=args.debug)\n",
    "    matcher = EmbeddingMatcher(out_dim=256).to(device).eval()\n",
    "\n",
    "    temp_head = TemporalHead(in_dim=6, proj_dim=32, hidden=64).to(device)\n",
    "    iou_head  = IoUHead(in_dim=6, hidden=64).to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(list(temp_head.parameters()) + list(iou_head.parameters()), lr=args.lr)\n",
    "    bce = nn.BCELoss(); l1 = nn.L1Loss()\n",
    "\n",
    "    gt_entries = load_annotations_json(args.data_root)\n",
    "\n",
    "    def collect_samples(video_ids, max_frames_per_vid=400):\n",
    "        X_temp = []; Y_temp = []\n",
    "        X_iou  = []; Y_iou  = []\n",
    "        for vid in video_ids:\n",
    "            refs = load_refs_for_episode(args.data_root, vid)\n",
    "            tmpl = build_template(matcher, refs, device=device, augs_per_ref=12, use_adapter=True, debug=args.debug)\n",
    "            vpath = video_path_for_episode(args.data_root, vid)\n",
    "            cap = cv2.VideoCapture(vpath)\n",
    "            gt_map = frame_to_boxes(gt_entries, vid, key=\"annotations\")\n",
    "            last_geom = None\n",
    "            seq_buf = []\n",
    "            fidx = 0\n",
    "            while True:\n",
    "                ok, frame = cap.read()\n",
    "                if not ok: break\n",
    "                fidx += 1  # 1-based index\n",
    "                boxes = props_engine(frame)\n",
    "                crops = [frame[y1:y2, x1:x2] for (x1,y1,x2,y2) in boxes]\n",
    "                t0=time.time()\n",
    "                embs  = matcher.encode_np(crops, device)\n",
    "                cos   = (embs @ tmpl.T).squeeze(1).detach().cpu().numpy() if embs.numel()>0 else np.zeros((0,), dtype=np.float32)\n",
    "                if args.debug:\n",
    "                    print(f\"[EMBED] vid={vid} f={fidx} props={len(boxes)} embed_time={time.time()-t0:.3f}s\")\n",
    "                H,W = frame.shape[:2]\n",
    "                feat_rows=[]; geoms=[]\n",
    "                for b,s in zip(boxes, cos):\n",
    "                    x1,y1,x2,y2 = b\n",
    "                    cx=(x1+x2)/2.0; cy=(y1+y2)/2.0; w=max(1.0,x2-x1); h=max(1.0,y2-y1)\n",
    "                    if last_geom is None:\n",
    "                        dx=dy=ds=dh=dw=0.0\n",
    "                    else:\n",
    "                        lcx,lcy,lw,lh = last_geom\n",
    "                        dx=(cx-lcx)/max(1.0,W); dy=(cy-lcy)/max(1.0,H)\n",
    "                        ds=math.log(w/max(1.0,lw)); dh=math.log(h/max(1.0,lh))\n",
    "                        dw=math.log((w/h)/max(1e-6,lw/lh))\n",
    "                    feat_rows.append([float(s),dx,dy,ds,dh,dw]); geoms.append((cx,cy,w,h))\n",
    "                y_bin, y_iou = label_frame_candidates(gt_map, fidx, boxes)\n",
    "                if feat_rows:\n",
    "                    top = max(range(len(feat_rows)), key=lambda i: feat_rows[i][0])\n",
    "                    seq_buf.append(feat_rows[top])\n",
    "                    if len(seq_buf) > args.temporal_T: seq_buf.pop(0)\n",
    "                    for fr, yb, yi in zip(feat_rows, y_bin, y_iou):\n",
    "                        X_iou.append(torch.tensor(fr, dtype=torch.float32))\n",
    "                        Y_iou.append(torch.tensor([yi], dtype=torch.float32))\n",
    "                        if len(seq_buf)>=3:\n",
    "                            X_temp.append(torch.tensor(seq_buf, dtype=torch.float32))\n",
    "                            Y_temp.append(torch.tensor([yb], dtype=torch.float32))\n",
    "                    last_geom = geoms[top]\n",
    "            cap.release()\n",
    "        return X_temp, Y_temp, X_iou, Y_iou\n",
    "\n",
    "    print(\"[COLLECT] train samples...\")\n",
    "    Xtemp_tr, Ytemp_tr, Xiou_tr, Yiou_tr = collect_samples(train_ids)\n",
    "    print(\"[COLLECT] val samples...\")\n",
    "    Xtemp_va, Ytemp_va, Xiou_va, Yiou_va = collect_samples(val_ids)\n",
    "\n",
    "    def batches(Xs, Ys, bs):\n",
    "        idx = np.arange(len(Xs)); np.random.shuffle(idx)\n",
    "        for i in range(0, len(idx), bs):\n",
    "            sl = idx[i:i+bs]\n",
    "            yield [Xs[j] for j in sl], [Ys[j] for j in sl]\n",
    "\n",
    "    for ep in range(1, args.epochs+1):\n",
    "        temp_head.train(); iou_head.train()\n",
    "        loss_sum=0.0; nsteps=0\n",
    "        for Xb, Yb in batches(Xtemp_tr, Ytemp_tr, args.batch_size):\n",
    "            Xpad = torch.nn.utils.rnn.pad_sequence([x for x in Xb], batch_first=True).to(device)\n",
    "            Ypad = torch.stack(Yb, dim=0).to(device)\n",
    "            opt.zero_grad(); yhat = temp_head(Xpad); loss = bce(yhat, Ypad)\n",
    "            loss.backward(); opt.step(); loss_sum += float(loss.item()); nsteps+=1\n",
    "        for Xb, Yb in batches(Xiou_tr, Yiou_tr, args.batch_size):\n",
    "            X = torch.stack(Xb, dim=0).to(device); Y = torch.stack(Yb, dim=0).to(device)\n",
    "            opt.zero_grad(); yhat = iou_head(X); loss = l1(yhat, Y)\n",
    "            loss.backward(); opt.step(); loss_sum += float(loss.item()); nsteps+=1\n",
    "        temp_head.eval(); iou_head.eval()\n",
    "        with torch.no_grad():\n",
    "            def eval_head(Xs, Ys, head, is_temp=True):\n",
    "                if not Xs: return 0.0\n",
    "                acc=0.0; n=0\n",
    "                if is_temp:\n",
    "                    for i in range(0,len(Xs),args.batch_size):\n",
    "                        X = torch.nn.utils.rnn.pad_sequence(Xs[i:i+args.batch_size], batch_first=True).to(device)\n",
    "                        Y = torch.stack(Ys[i:i+args.batch_size], dim=0).to(device)\n",
    "                        yhat = head(X); acc += float(((yhat>0.5)==(Y>0.5)).float().mean().cpu()); n+=1\n",
    "                else:\n",
    "                    for i in range(0,len(Xs),args.batch_size):\n",
    "                        X = torch.stack(Xs[i:i+args.batch_size], dim=0).to(device)\n",
    "                        Y = torch.stack(Ys[i:i+args.batch_size], dim=0).to(device)\n",
    "                        yhat = head(X); acc += float(1.0 - torch.abs(yhat-Y).mean().cpu()); n+=1\n",
    "                return acc/max(1,n)\n",
    "            t_acc = eval_head(Xtemp_va, Ytemp_va, temp_head, True)\n",
    "            q_acc = eval_head(Xiou_va,  Yiou_va,  iou_head,  False)\n",
    "        print(f\"[E{ep}] loss={loss_sum/max(1,nsteps):.4f}  temp_val_acc={t_acc:.3f}  iou_val(1-L1)={q_acc:.3f}\")\n",
    "\n",
    "    torch.save({\"temporal_head\": temp_head.state_dict(), \"iou_head\": iou_head.state_dict()}, args.save_ckpt)\n",
    "    print(f\"[SAVED] {args.save_ckpt}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from pathlib import Path\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b222f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2, math, time\n",
    "\n",
    "from common import (\n",
    "    set_seed, find_episodes, load_annotations_json, load_refs_for_episode,\n",
    "    video_path_for_episode, YOLOProposals, EmbeddingMatcher, build_template,\n",
    "    nms_xyxy, frame_to_boxes, TemporalHead, IoUHead, SingleTargetTracker,\n",
    "    segmentize, st_iou_mean\n",
    ")\n",
    "\n",
    "\n",
    "def run_once(args, video_ids, ckpt=None, tau_high=0.55, tau_low=0.45):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    props = YOLOProposals(conf=args.conf, iou=args.nms_iou, imgsz=args.imgsz,\n",
    "                          max_candidates=args.max_props, device=0,\n",
    "                          yolo_on=not args.yolo_off, yolo_ckpt=args.yolo_ckpt, debug=args.debug)\n",
    "    matcher = EmbeddingMatcher(out_dim=256).to(device).eval()\n",
    "    temp_head = TemporalHead().to(device).eval()\n",
    "    iou_head  = IoUHead().to(device).eval()\n",
    "    if ckpt:\n",
    "        sd = torch.load(ckpt, map_location=device)\n",
    "        temp_head.load_state_dict(sd[\"temporal_head\"]) ; iou_head.load_state_dict(sd[\"iou_head\"])\n",
    "\n",
    "    preds=[]\n",
    "    for vid in video_ids:\n",
    "        refs = load_refs_for_episode(args.data_root, vid)\n",
    "        tmpl = build_template(matcher, refs, device=device, augs_per_ref=12, use_adapter=True, debug=args.debug)\n",
    "        cap = cv2.VideoCapture(video_path_for_episode(args.data_root, vid))\n",
    "        tracker = SingleTargetTracker(tau_high=tau_high, tau_low=tau_low,\n",
    "                                      assoc_lambda=args.assoc_lambda, max_lost=max(10,3*args.frame_stride),\n",
    "                                      min_commit=2, gap_fill=max(1,args.frame_stride-1),\n",
    "                                      frame_stride=args.frame_stride, debug=args.debug)\n",
    "        seq_buf=[]; last_geom=None; fidx=0\n",
    "        while True:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok: break\n",
    "            fidx += 1  # 1-based\n",
    "            if args.frame_stride>1 and ((fidx-1) % args.frame_stride)!=0:\n",
    "                continue\n",
    "            t0=time.time(); boxes = props(frame); t_prop=time.time()-t0\n",
    "            crops = [frame[y1:y2, x1:x2] for (x1,y1,x2,y2) in boxes]\n",
    "            t1=time.time(); embs  = matcher.encode_np(crops, device); t_emb=time.time()-t1\n",
    "            cos   = (embs @ tmpl.T).squeeze(1).detach().cpu().numpy() if embs.numel()>0 else np.zeros((0,),dtype=np.float32)\n",
    "            H,W = frame.shape[:2]; feat_rows=[]\n",
    "            for b,s in zip(boxes, cos):\n",
    "                x1,y1,x2,y2=b\n",
    "                cx=(x1+x2)/2; cy=(y1+y2)/2; w=max(1.0,x2-x1); h=max(1.0,y2-y1)\n",
    "                if last_geom is None:\n",
    "                    dx=dy=ds=dh=dw=0.0\n",
    "                else:\n",
    "                    lcx,lcy,lw,lh = last_geom\n",
    "                    dx=(cx-lcx)/max(1.0,W); dy=(cy-lcy)/max(1.0,H)\n",
    "                    ds=math.log(w/max(1.0,lw)); dh=math.log(h/max(1.0,lh))\n",
    "                    dw=math.log((w/h)/max(1e-6,lw/lh))\n",
    "                feat_rows.append([float(s),dx,dy,ds,dh,dw])\n",
    "            keep = nms_xyxy(boxes, cos, iou_thr=args.nms_final_iou)\n",
    "            boxes = [boxes[i] for i in keep]; sims=[float(cos[i]) for i in keep]\n",
    "            feats=[feat_rows[i] for i in keep]\n",
    "            if feats:\n",
    "                seq_buf.append(feats[0])\n",
    "                if len(seq_buf)>args.temporal_T: seq_buf.pop(0)\n",
    "                seq = torch.tensor(seq_buf, dtype=torch.float32, device=device).unsqueeze(0).repeat(len(feats),1,1)\n",
    "                s_temp = temp_head(seq).squeeze(-1).detach().cpu().numpy()\n",
    "                s_iou  = iou_head(torch.tensor(feats, dtype=torch.float32, device=device)).squeeze(-1).detach().cpu().numpy()\n",
    "                fused = (args.alpha_fuse*np.array(sims) + (1-args.alpha_fuse)*s_temp) * 0.5 + 0.5*s_iou\n",
    "            else:\n",
    "                fused=[]\n",
    "            tracker.update(fidx, boxes, fused)\n",
    "            if boxes:\n",
    "                bi = int(np.argmax(fused)); x1,y1,x2,y2 = boxes[bi]\n",
    "                last_geom=((x1+x2)/2,(y1+y2)/2,max(1.0,x2-x1),max(1.0,y2-y1))\n",
    "            if args.debug and (fidx % (5*args.frame_stride) == 1):\n",
    "                print(f\"[DBG] {vid} f={fidx} props={len(boxes)} t_prop={t_prop:.3f}s t_emb={t_emb:.3f}s\")\n",
    "        cap.release()\n",
    "        dets = tracker.detections\n",
    "        segs = segmentize(dets, max_gap=args.frame_stride)\n",
    "        preds.append({\"video_id\": vid, \"detections\": segs})\n",
    "        if args.debug:\n",
    "            sample_frames = []\n",
    "            for s in segs:\n",
    "                for bb in s[\"bboxes\"]:\n",
    "                    sample_frames.append(bb[\"frame\"]) ;\n",
    "                    if len(sample_frames)>=5: break\n",
    "                if len(sample_frames)>=5: break\n",
    "            print(f\"[DBG] {vid}: det_frames={sum(len(s['bboxes']) for s in segs)} sample={sample_frames}\")\n",
    "    return preds\n",
    "\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--data_root\", required=True)\n",
    "    ap.add_argument(\"--split_file\", required=True)\n",
    "    ap.add_argument(\"--ckpt\", default=\"./ckpts/heads_dev.pt\")\n",
    "    ap.add_argument(\"--frame_stride\", type=int, default=2)\n",
    "    ap.add_argument(\"--imgsz\", type=int, default=960)\n",
    "    ap.add_argument(\"--max_props\", type=int, default=200)\n",
    "    ap.add_argument(\"--conf\", type=float, default=0.005)\n",
    "    ap.add_argument(\"--nms_iou\", type=float, default=0.60)\n",
    "    ap.add_argument(\"--nms_final_iou\", type=float, default=0.5)\n",
    "    ap.add_argument(\"--assoc_lambda\", type=float, default=0.5)\n",
    "    ap.add_argument(\"--alpha_fuse\", type=float, default=0.5)\n",
    "    ap.add_argument(\"--temporal_T\", type=int, default=15)\n",
    "    ap.add_argument(\"--yolo_ckpt\", type=str, default=None)\n",
    "    ap.add_argument(\"--yolo_off\", action='store_true')\n",
    "    ap.add_argument(\"--debug\", action='store_true')\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    with open(args.split_file,\"r\",encoding=\"utf-8\") as f: sp=json.load(f)\n",
    "    val_ids = sp[\"val_ids\"]\n",
    "    gt = load_annotations_json(args.data_root)\n",
    "\n",
    "    # Debug GT coverage\n",
    "    if args.debug and len(val_ids)>0:\n",
    "        v0 = val_ids[0]\n",
    "        gmap = frame_to_boxes(gt, v0, key=\"annotations\")\n",
    "        frames = sorted(gmap.keys())\n",
    "        print(f\"[DEBUG] {v0}: GT frames={len(frames)} min={frames[0] if frames else None} max={frames[-1] if frames else None}\")\n",
    "\n",
    "    best=(0.0, None)\n",
    "    for th in [0.45,0.5,0.55]:\n",
    "        for tl in [th-0.15, th-0.1, th-0.05]:\n",
    "            preds = run_once(args, val_ids, ckpt=args.ckpt, tau_high=th, tau_low=tl)\n",
    "            sc = st_iou_mean(gt, preds, val_ids)\n",
    "            print(f\"[VAL] tau_high={th:.2f} tau_low={tl:.2f}  ST-IoU={sc:.4f}\")\n",
    "            if sc > best[0]: best=(sc,(th,tl))\n",
    "\n",
    "    print(\"\\n[BEST]\", best)\n",
    "    cfg = {\n",
    "        \"frame_stride\": args.frame_stride,\n",
    "        \"imgsz\": args.imgsz,\n",
    "        \"max_props\": args.max_props,\n",
    "        \"conf\": args.conf,\n",
    "        \"nms_iou\": args.nms_iou,\n",
    "        \"nms_final_iou\": args.nms_final_iou,\n",
    "        \"assoc_lambda\": args.assoc_lambda,\n",
    "        \"alpha_fuse\": args.alpha_fuse,\n",
    "        \"temporal_T\": args.temporal_T,\n",
    "        \"tau_high\": best[1][0] if best[1] else 0.55,\n",
    "        \"tau_low\":  best[1][1] if best[1] else 0.45\n",
    "    }\n",
    "    print(\"\\n[CONFIG] Paste into configs/release.json:\\n\" + json.dumps(cfg, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401decc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2, math, time\n",
    "from pathlib import Path\n",
    "\n",
    "from common import (\n",
    "    find_episodes, load_refs_for_episode, video_path_for_episode,\n",
    "    YOLOProposals, EmbeddingMatcher, build_template, nms_xyxy,\n",
    "    TemporalHead, IoUHead, SingleTargetTracker, segmentize\n",
    ")\n",
    "\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--data_root\", required=True)\n",
    "    ap.add_argument(\"--ckpt\", required=True)\n",
    "    ap.add_argument(\"--config\", required=True)\n",
    "    ap.add_argument(\"--out\", default=\"./viz_test/predictions.json\")\n",
    "    ap.add_argument(\"--yolo_ckpt\", type=str, default=None)\n",
    "    ap.add_argument(\"--yolo_off\", action='store_true')\n",
    "    ap.add_argument(\"--debug\", action='store_true')\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    Path(args.out).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(args.config,\"r\",encoding=\"utf-8\") as f: C = json.load(f)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    props = YOLOProposals(conf=C[\"conf\"], iou=C[\"nms_iou\"], imgsz=C[\"imgsz\"],\n",
    "                          max_candidates=C[\"max_props\"], device=0,\n",
    "                          yolo_on=not args.yolo_off, yolo_ckpt=args.yolo_ckpt, debug=args.debug)\n",
    "    matcher = EmbeddingMatcher(out_dim=256).to(device).eval()\n",
    "    temp_head = TemporalHead().to(device).eval()\n",
    "    iou_head  = IoUHead().to(device).eval()\n",
    "    sd = torch.load(args.ckpt, map_location=device)\n",
    "    temp_head.load_state_dict(sd[\"temporal_head\"]) ; iou_head.load_state_dict(sd[\"iou_head\"])\n",
    "\n",
    "    vids = find_episodes(args.data_root)\n",
    "    preds=[]\n",
    "    for vid in vids:\n",
    "        print(f\"[RUN] {vid}\")\n",
    "        refs = load_refs_for_episode(args.data_root, vid)\n",
    "        tmpl = build_template(matcher, refs, device=device, augs_per_ref=12, use_adapter=True, debug=args.debug)\n",
    "        cap = cv2.VideoCapture(video_path_for_episode(args.data_root, vid))\n",
    "        tracker = SingleTargetTracker(\n",
    "                tau_high=C[\"tau_high\"], tau_low=C[\"tau_low\"],\n",
    "                assoc_lambda=C[\"assoc_lambda\"],\n",
    "                max_lost=int(C.get(\"max_lost\", max(10, 3*C[\"frame_stride\"]))),\n",
    "                min_commit=int(C.get(\"min_commit\", 2)),\n",
    "                gap_fill=max(1, C[\"frame_stride\"]-1),\n",
    "                frame_stride=C[\"frame_stride\"],\n",
    "                debug=args.debug\n",
    "            )\n",
    "        seq_buf=[]; last_geom=None; fidx=0\n",
    "        while True:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok: break\n",
    "            fidx += 1  # 1-based\n",
    "            if C[\"frame_stride\"]>1 and ((fidx-1) % C[\"frame_stride\"])!=0:\n",
    "                continue\n",
    "            t0=time.time(); boxes = props(frame); t_prop=time.time()-t0\n",
    "            crops = [frame[y1:y2, x1:x2] for (x1,y1,x2,y2) in boxes]\n",
    "            t1=time.time(); embs  = matcher.encode_np(crops, device); t_emb=time.time()-t1\n",
    "            cos   = (embs @ tmpl.T).squeeze(1).detach().cpu().numpy() if embs.numel()>0 else np.zeros((0,),dtype=np.float32)\n",
    "            H,W = frame.shape[:2]; feat_rows=[]\n",
    "            for b,s in zip(boxes, cos):\n",
    "                x1,y1,x2,y2=b\n",
    "                cx=(x1+x2)/2; cy=(y1+y2)/2; w=max(1.0,x2-x1); h=max(1.0,y2-y1)\n",
    "                if last_geom is None:\n",
    "                    dx=dy=ds=dh=dw=0.0\n",
    "                else:\n",
    "                    lcx,lcy,lw,lh = last_geom\n",
    "                    dx=(cx-lcx)/max(1.0,W); dy=(cy-lcy)/max(1.0,H)\n",
    "                    ds=math.log(w/max(1.0,lw)); dh=math.log(h/max(1.0,lh))\n",
    "                    dw=math.log((w/h)/max(1e-6,lw/lh))\n",
    "                feat_rows.append([float(s),dx,dy,ds,dh,dw])\n",
    "            keep = nms_xyxy(boxes, cos, iou_thr=C[\"nms_final_iou\"]) \n",
    "            boxes = [boxes[i] for i in keep]; sims=[float(cos[i]) for i in keep]\n",
    "            feats=[feat_rows[i] for i in keep]\n",
    "            if feats:\n",
    "                seq_buf.append(feats[0])\n",
    "                if len(seq_buf)>C[\"temporal_T\"]: seq_buf.pop(0)\n",
    "                seq = torch.tensor(seq_buf, dtype=torch.float32, device=device).unsqueeze(0).repeat(len(feats),1,1)\n",
    "                s_temp = temp_head(seq).squeeze(-1).detach().cpu().numpy()\n",
    "                s_iou  = iou_head(torch.tensor(feats, dtype=torch.float32, device=device)).squeeze(-1).detach().cpu().numpy()\n",
    "                fused = (C[\"alpha_fuse\"]*np.array(sims) + (1-C[\"alpha_fuse\"]) * s_temp) * 0.5 + 0.5*s_iou\n",
    "            else:\n",
    "                fused=[]\n",
    "                \n",
    "            # ---- Tracker debug (every 20th kept frame) ----\n",
    "            if isinstance(fused, list):\n",
    "                top_score = -1.0 if len(fused) == 0 else float(np.max(fused))\n",
    "            else:\n",
    "                top_score = -1.0 if (fused is None or len(fused) == 0) else float(np.max(fused))\n",
    "            if args.debug and (fidx % (20 * max(1, C[\"frame_stride\"])) == 0):\n",
    "                state = getattr(tracker, \"state\", \"NA\")\n",
    "                curr_len = getattr(tracker, \"curr_len\", 0)\n",
    "                print(\n",
    "                    f\"[TRK] vid={vid} f={fidx} top_s={top_score:.3f} \"\n",
    "                    f\"state={state} tauH={C['tau_high']:.2f} tauL={C['tau_low']:.2f} \"\n",
    "                    f\"len={curr_len}\"\n",
    "                )\n",
    "            # -----------------------------------------------\n",
    "            tracker.update(fidx, boxes, fused)\n",
    "            if boxes:\n",
    "                bi = int(np.argmax(fused)); x1,y1,x2,y2 = boxes[bi]\n",
    "                last_geom=((x1+x2)/2,(y1+y2)/2,max(1.0,x2-x1),max(1.0,y2-y1))\n",
    "            if args.debug and (fidx % (5*C[\"frame_stride\"]) == 1):\n",
    "                print(f\"[DBG] {vid} f={fidx} props={len(boxes)} t_prop={t_prop:.3f}s t_emb={t_emb:.3f}s\")\n",
    "        cap.release()\n",
    "        segs = segmentize(tracker.detections, max_gap=C[\"frame_stride\"]) \n",
    "        preds.append({\"video_id\": vid, \"detections\": segs})\n",
    "        out_path = Path(args.out); tmp = out_path.with_suffix(\".tmp.json\")\n",
    "        cur = []\n",
    "        if out_path.exists():\n",
    "            try:\n",
    "                with open(out_path,\"r\",encoding=\"utf-8\") as f: cur=json.load(f)\n",
    "            except Exception: cur=[]\n",
    "        cur = [e for e in cur if e.get(\"video_id\") != vid]\n",
    "        cur.append({\"video_id\": vid, \"detections\": segs})\n",
    "        with open(tmp,\"w\",encoding=\"utf-8\") as f: json.dump(cur, f, indent=2)\n",
    "        tmp.replace(out_path)\n",
    "        print(f\"[DONE] {vid}: {sum(len(s['bboxes']) for s in segs)} boxes, {len(segs)} segments\")\n",
    "    with open(args.out,\"w\",encoding=\"utf-8\") as f: json.dump(preds, f, indent=2)\n",
    "    print(f\"[SAVE] {args.out}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
